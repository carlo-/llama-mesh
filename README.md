# LLaMa-Mesh macOS

Simple macOS wrapper for LLaMa-Mesh ([GitHub](https://github.com/nv-tlabs/LLaMa-Mesh?tab=readme-ov-file), [paper](https://arxiv.org/abs/2411.09595)) based on [llama.cpp](https://github.com/ggerganov/llama.cpp).

---

You can download quantized weights (GGUF) from HuggingFace, for example [here](https://huggingface.co/bartowski/LLaMA-Mesh-GGUF).

I would recommend 4-bit quantized weights at a minimum, 6- or 8-bit for best results.

![CleanShot 2024-11-21 at 21 21 17@2x](https://github.com/user-attachments/assets/29734258-2872-4244-a7a9-88049f7a85b7)

---
